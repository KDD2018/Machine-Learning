{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "from gensim import corpora, models, similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['所有者权益合计', '股东权益合计', '所有者权益（或股东权益)合计']"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1 = ['所有者权益合计','股东权益合计','所有者权益（或股东权益)合计']\n",
    "l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['所有者', '权益', '合计'], ['股东权益', '合计'], ['所有者', '权益', '（', '或', '股东权益', ')', '合计']]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "all_doc_list = []  #\n",
    "for doc in l1:\n",
    "    # 利用jieba分词将语料库中的每一个问题切割\n",
    "    doc_list = [word for word in jieba.cut(doc)]\n",
    "    all_doc_list.append(doc_list)\n",
    "print(all_doc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['归属于', '母公司', '所有者', '权益', '合计']\n"
     ]
    }
   ],
   "source": [
    "# 用户问的问题\n",
    "a = \"归属于母公司所有者权益合计\"\n",
    "doc_test_list = [word for word in jieba.cut(a)]\n",
    "print(doc_test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token2id {'合计': 0, '所有者': 1, '权益': 2, '股东权益': 3, ')': 4, '或': 5, '（': 6}\n"
     ]
    }
   ],
   "source": [
    "# 制作语料库\n",
    "dictionary = corpora.Dictionary(all_doc_list)  # 制作词袋\n",
    "# 词袋:是根据当前所有的问题即列表all_doc_list中每一个列表中的每一个元素(就是字)为他们做一个唯一的标志,形成一个key:velue的字典\n",
    "print(\"token2id\", dictionary.token2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus [[(0, 1), (1, 1), (2, 1)], [(0, 1), (3, 1)], [(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1)]] <class 'list'>\n"
     ]
    }
   ],
   "source": [
    "# 制作语料库\n",
    "# 这里是将all_doc_list 中的每一个列表中的词语 与 dictionary 中的Key进行匹配\n",
    "# doc2bow文本变成id,这个词在当前的列表中出现的次数\n",
    "# ['你', '的', '名字', '是', '什么'] ==>(1,1),(4,1),(2,1),(3,1),(0,1)\n",
    "# 1是你 1代表出现一次, 4是的  1代表出现了一次, 以此类推 2是名字 , 3是是,0是什么\n",
    "corpus = [dictionary.doc2bow(doc) for doc in all_doc_list]\n",
    "print(\"corpus\", corpus, type(corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doc_test_vec [(0, 1), (1, 1), (2, 1)] <class 'list'>\n"
     ]
    }
   ],
   "source": [
    "# ['你', '今年', '多大', '了']  词袋中没有多大165\n",
    "# 所以需要词向量化\n",
    "\n",
    "# 将需要寻找相似度的分词列表 做成 语料库 doc_test_vec\n",
    "# ['你', '今年', '多大', '了']  (1, 1), (5, 1), (6, 1)\n",
    "doc_test_vec = dictionary.doc2bow(doc_test_list)\n",
    "print(\"doc_test_vec\", doc_test_vec, type(doc_test_vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lsi LsiModel(num_terms=7, num_topics=200, decay=1.0, chunksize=20000) <class 'gensim.models.lsimodel.LsiModel'>\n"
     ]
    }
   ],
   "source": [
    "# 将corpus语料库(初识语料库) 使用Lsi模型进行训练,将语料库变成计算机可识别可读的数字\n",
    "lsi = models.LsiModel(corpus)\n",
    "print(\"lsi\", lsi, type(lsi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lsi[corpus] <gensim.interfaces.TransformedCorpus object at 0x7ff5f2ad9950>\n"
     ]
    }
   ],
   "source": [
    "# 语料库corpus的训练结果\n",
    "print(\"lsi[corpus]\", lsi[corpus])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lsi[doc_test_vec] [(0, 1.3688940110590953), (1, -1.0079078146174605), (2, -0.33204069587867663)]\n"
     ]
    }
   ],
   "source": [
    "# 将问题放到放到已经训练好的语料库模型一个一个匹配,获取匹配分值\n",
    "# 获得语料库doc_test_vec 在 语料库corpus的训练结果 中的 向量表示\n",
    "print(\"lsi[doc_test_vec]\", lsi[doc_test_vec])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index <gensim.similarities.docsim.SparseMatrixSimilarity object at 0x7ff5f70bd890> <class 'gensim.similarities.docsim.SparseMatrixSimilarity'>\n"
     ]
    }
   ],
   "source": [
    "# lsi[corpus]==>Lsi训练好的语料库模型\n",
    "# index是设定的匹配相识度的条件\n",
    "index = similarities.SparseMatrixSimilarity(lsi[corpus], num_features=len(dictionary.keys()))\n",
    "print(\"index\", index, type(index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1.3688940110590953), (1, -1.0079078146174605), (2, -0.33204069587867663)]\n",
      "sim [1.         0.40824825 0.65465367] <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# 将 语料库doc_test_vec 在 语料库corpus的训练结果 中的 向量表示 与 语料库corpus的 向量表示 做矩阵相似度计算\n",
    "gongyinshi = lsi[doc_test_vec]\n",
    "print(gongyinshi)\n",
    "sim = index[gongyinshi]\n",
    "\n",
    "print(\"sim\", sim, type(sim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1.0), (2, 0.65465367), (1, 0.40824825)]\n"
     ]
    }
   ],
   "source": [
    "# 对下标和相似度结果进行一个排序,拿出相似度最高的结果\n",
    "# cc = sorted(enumerate(sim), key=lambda item: item[1],reverse=True)\n",
    "cc = sorted(enumerate(sim), key=lambda item: -item[1])\n",
    "print(cc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "归属于母公司所有者权益合计 所有者权益合计\n"
     ]
    }
   ],
   "source": [
    "text = l1[cc[0][0]]\n",
    "if cc[0][1] > 0:\n",
    "    print(a, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from gensim import corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [\n",
    "    \"Human machine interface for lab abc computer applications\",\n",
    "    \"A survey of user opinion of computer system response time\",\n",
    "    \"The EPS user interface management system\",\n",
    "    \"System and human system engineering testing of EPS\",\n",
    "    \"Relation of user perceived response time to error measurement\",\n",
    "    \"The generation of random binary unordered trees\",\n",
    "    \"The intersection graph of paths in trees\",\n",
    "    \"Graph minors IV Widths of trees and well quasi ordering\",\n",
    "    \"Graph minors A survey\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove common words and tokenize\n",
    "stoplist = set('for a of the and to in'.split())\n",
    "texts = [\n",
    "    [word for word in document.lower().split() if word not in stoplist]\n",
    "    for document in documents\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['human', 'machine', 'interface', 'lab', 'abc', 'computer', 'applications'],\n",
       " ['survey', 'user', 'opinion', 'computer', 'system', 'response', 'time'],\n",
       " ['eps', 'user', 'interface', 'management', 'system'],\n",
       " ['system', 'human', 'system', 'engineering', 'testing', 'eps'],\n",
       " ['relation', 'user', 'perceived', 'response', 'time', 'error', 'measurement'],\n",
       " ['generation', 'random', 'binary', 'unordered', 'trees'],\n",
       " ['intersection', 'graph', 'paths', 'trees'],\n",
       " ['graph', 'minors', 'iv', 'widths', 'trees', 'well', 'quasi', 'ordering'],\n",
       " ['graph', 'minors', 'survey']]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'int'>, {'human': 2, 'machine': 1, 'interface': 2, 'lab': 1, 'abc': 1, 'computer': 2, 'applications': 1, 'survey': 2, 'user': 3, 'opinion': 1, 'system': 4, 'response': 2, 'time': 2, 'eps': 2, 'management': 1, 'engineering': 1, 'testing': 1, 'relation': 1, 'perceived': 1, 'error': 1, 'measurement': 1, 'generation': 1, 'random': 1, 'binary': 1, 'unordered': 1, 'trees': 3, 'intersection': 1, 'graph': 3, 'paths': 1, 'minors': 2, 'iv': 1, 'widths': 1, 'well': 1, 'quasi': 1, 'ordering': 1})\n"
     ]
    }
   ],
   "source": [
    "# remove words that appear only once\n",
    "frequency = defaultdict(int)\n",
    "for text in texts:\n",
    "    for token in text:\n",
    "        frequency[token] += 1\n",
    "print(frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\n",
    "    [token for token in text if frequency[token] > 1]\n",
    "    for text in texts\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['human', 'interface', 'computer'],\n",
       " ['survey', 'user', 'computer', 'system', 'response', 'time'],\n",
       " ['eps', 'user', 'interface', 'system'],\n",
       " ['system', 'human', 'system', 'eps'],\n",
       " ['user', 'response', 'time'],\n",
       " ['trees'],\n",
       " ['graph', 'trees'],\n",
       " ['graph', 'minors', 'trees'],\n",
       " ['graph', 'minors', 'survey']]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.corpora.dictionary.Dictionary at 0x7ff5f0afe490>"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'computer': 0,\n",
       " 'human': 1,\n",
       " 'interface': 2,\n",
       " 'response': 3,\n",
       " 'survey': 4,\n",
       " 'system': 5,\n",
       " 'time': 6,\n",
       " 'user': 7,\n",
       " 'eps': 8,\n",
       " 'trees': 9,\n",
       " 'graph': 10,\n",
       " 'minors': 11}"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary.token2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0, 1), (1, 1), (2, 1)],\n",
       " [(0, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1)],\n",
       " [(2, 1), (5, 1), (7, 1), (8, 1)],\n",
       " [(1, 1), (5, 2), (8, 1)],\n",
       " [(3, 1), (6, 1), (7, 1)],\n",
       " [(9, 1)],\n",
       " [(9, 1), (10, 1)],\n",
       " [(9, 1), (10, 1), (11, 1)],\n",
       " [(4, 1), (10, 1), (11, 1)]]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsi = models.LsiModel(corpus, id2word=dictionary, num_topics=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.46182100453271613), (1, -0.07002766527900031)]\n"
     ]
    }
   ],
   "source": [
    "doc = \"Human computer interaction\"\n",
    "vec_bow = dictionary.doc2bow(doc.lower().split())\n",
    "vec_lsi = lsi[vec_bow]  # convert the query to LSI space\n",
    "print(vec_lsi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = similarities.MatrixSimilarity(lsi[corpus])  # transform corpus to LSI space and index it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.998093), (1, 0.93748635), (2, 0.9984453), (3, 0.9865886), (4, 0.90755945), (5, -0.12416792), (6, -0.10639259), (7, -0.09879464), (8, 0.050041765)]\n"
     ]
    }
   ],
   "source": [
    "sims = index[vec_lsi]  # perform a similarity query against the corpus\n",
    "print(list(enumerate(sims)))  # print (document_number, document_similarity) 2-tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 0.9984453) Human machine interface for lab abc computer applications\n",
      "(0, 0.998093) A survey of user opinion of computer system response time\n",
      "(3, 0.9865886) The EPS user interface management system\n",
      "(1, 0.93748635) System and human system engineering testing of EPS\n",
      "(4, 0.90755945) Relation of user perceived response time to error measurement\n",
      "(8, 0.050041765) The generation of random binary unordered trees\n",
      "(7, -0.09879464) The intersection graph of paths in trees\n",
      "(6, -0.10639259) Graph minors IV Widths of trees and well quasi ordering\n",
      "(5, -0.12416792) Graph minors A survey\n"
     ]
    }
   ],
   "source": [
    "sims = sorted(enumerate(sims), key=lambda item: -item[1])\n",
    "for i, s in enumerate(sims):\n",
    "    print(s, documents[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
